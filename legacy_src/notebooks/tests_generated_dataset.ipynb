{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from fairlearn.metrics import demographic_parity_ratio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import set_seed, generate_sensitive_feature\n",
    "from KnowledgeBase import KnowledgeBase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_hp = dict(\n",
    "    dataset_SAMPLES=500,\n",
    "    dataset_FEATURES=3,\n",
    "    dataset_n_informative=2,\n",
    "    dataset_n_redundant=1,\n",
    "    dataset_flip_y=0.001,\n",
    "    perfect_classifier_demographic_parity=0.5,\n",
    "    hidden_layer_sizes=(10, 5)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = make_classification(\n",
    "    n_samples=wandb_hp['dataset_SAMPLES'],\n",
    "    n_features=wandb_hp['dataset_FEATURES'],\n",
    "    n_informative=wandb_hp['dataset_n_informative'],\n",
    "    n_redundant=wandb_hp['dataset_n_redundant'],\n",
    "    flip_y=wandb_hp['dataset_flip_y']\n",
    ")\n",
    "\n",
    "p_attribute = generate_sensitive_feature(\n",
    "    Y, wandb_hp['perfect_classifier_demographic_parity'])\n",
    "\n",
    "# 0: privileged, 1: UNprivileged\n",
    "X = np.hstack([X, np.expand_dims(p_attribute, axis=-1)])\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    test_size=0.2,\n",
    "    stratify=np.char.add(p_attribute.astype(str), Y.astype(str)),\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_hp['ground_truth_demographic_parity'] = demographic_parity_ratio(Y, Y, sensitive_features=p_attribute)\n",
    "wandb_hp['trainset_demographic_parity'] = demographic_parity_ratio(Ytrain, Ytrain, sensitive_features=Xtrain[:, Xtrain.shape[1]-1])\n",
    "wandb_hp['testset_demographic_parity'] = demographic_parity_ratio(Ytest, Ytest, sensitive_features=Xtest[:, Xtest.shape[1]-1])\n",
    "print(f\"Ground truth demographic parity: {wandb_hp['ground_truth_demographic_parity']}\")\n",
    "print(f\"Trainset demographic parity: {wandb_hp['trainset_demographic_parity']}\")\n",
    "print(f\"Testset demographic parity: {wandb_hp['testset_demographic_parity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init the knowledge base\n",
    "kb = KnowledgeBase(\n",
    "    Xtrain, Xtest,\n",
    "    Ytrain, Ytest,\n",
    "    {'positive':1, 'negative':0},\n",
    "    0,\n",
    "    1,\n",
    "    hidden_layer_sizes=(50, 50),\n",
    "    sensitive_feature_index=Xtrain.shape[1]-1,\n",
    "    config_file='./KnowledgeBaseAxioms.json'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_hp['learning_rate'] = 0.001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=wandb_hp['learning_rate'])\n",
    "wandb_hp['optimizer'] = optimizer.__class__\n",
    "wandb_hp['epochs'] = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(tf.range(wandb_hp['epochs'])):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = 1. - kb.train_step()  # type: ignore\n",
    "    grads = tape.gradient(loss, kb.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, kb.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb.get_logs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
